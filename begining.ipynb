{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9506c24a-fe54-43bf-b55a-99e123cc9c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install geopy\n",
    "#pip install bs4\n",
    "#pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dc8a077-80c0-479d-8970-3f7cc10668e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from geopy.point import Point\n",
    "from geopy.geocoders import Nominatim\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5524be1c-f2b1-4435-b598-e93097a145ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jbrable/Documents/ENSAE_2AD/S1/python/UFO'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "809322fd-23b5-4d60-ae85-16f524114b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j3/7p5c8ygd7yg6bgkb6r90ddhm0000gn/T/ipykernel_35772/2315484744.py:1: DtypeWarning: Columns (5,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"data/ufo_sightings_scrubbed.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/ufo_sightings_scrubbed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e31feccc-eefd-4683-9f74-6df01f2b388c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration (seconds)</th>\n",
       "      <th>duration (hours/min)</th>\n",
       "      <th>comments</th>\n",
       "      <th>date posted</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949-10-10 20:30:00</td>\n",
       "      <td>san marcos</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>cylinder</td>\n",
       "      <td>2700</td>\n",
       "      <td>45 minutes</td>\n",
       "      <td>This event took place in early fall around 194...</td>\n",
       "      <td>2004-04-27</td>\n",
       "      <td>29.8830556</td>\n",
       "      <td>-97.941111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949-10-10 21:00:00</td>\n",
       "      <td>lackland afb</td>\n",
       "      <td>tx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>light</td>\n",
       "      <td>7200</td>\n",
       "      <td>1-2 hrs</td>\n",
       "      <td>1949 Lackland AFB&amp;#44 TX.  Lights racing acros...</td>\n",
       "      <td>2005-12-16</td>\n",
       "      <td>29.38421</td>\n",
       "      <td>-98.581082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1955-10-10 17:00:00</td>\n",
       "      <td>chester (uk/england)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gb</td>\n",
       "      <td>circle</td>\n",
       "      <td>20</td>\n",
       "      <td>20 seconds</td>\n",
       "      <td>Green/Orange circular disc over Chester&amp;#44 En...</td>\n",
       "      <td>2008-01-21</td>\n",
       "      <td>53.2</td>\n",
       "      <td>-2.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956-10-10 21:00:00</td>\n",
       "      <td>edna</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>circle</td>\n",
       "      <td>20</td>\n",
       "      <td>1/2 hour</td>\n",
       "      <td>My older brother and twin sister were leaving ...</td>\n",
       "      <td>2004-01-17</td>\n",
       "      <td>28.9783333</td>\n",
       "      <td>-96.645833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1960-10-10 20:00:00</td>\n",
       "      <td>kaneohe</td>\n",
       "      <td>hi</td>\n",
       "      <td>us</td>\n",
       "      <td>light</td>\n",
       "      <td>900</td>\n",
       "      <td>15 minutes</td>\n",
       "      <td>AS a Marine 1st Lt. flying an FJ4B fighter/att...</td>\n",
       "      <td>2004-01-22</td>\n",
       "      <td>21.4180556</td>\n",
       "      <td>-157.803611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime                  city state country     shape  \\\n",
       "0  1949-10-10 20:30:00            san marcos    tx      us  cylinder   \n",
       "1  1949-10-10 21:00:00          lackland afb    tx     NaN     light   \n",
       "2  1955-10-10 17:00:00  chester (uk/england)   NaN      gb    circle   \n",
       "3  1956-10-10 21:00:00                  edna    tx      us    circle   \n",
       "4  1960-10-10 20:00:00               kaneohe    hi      us     light   \n",
       "\n",
       "  duration (seconds) duration (hours/min)  \\\n",
       "0               2700           45 minutes   \n",
       "1               7200              1-2 hrs   \n",
       "2                 20           20 seconds   \n",
       "3                 20             1/2 hour   \n",
       "4                900           15 minutes   \n",
       "\n",
       "                                            comments date posted    latitude  \\\n",
       "0  This event took place in early fall around 194...  2004-04-27  29.8830556   \n",
       "1  1949 Lackland AFB&#44 TX.  Lights racing acros...  2005-12-16    29.38421   \n",
       "2  Green/Orange circular disc over Chester&#44 En...  2008-01-21        53.2   \n",
       "3  My older brother and twin sister were leaving ...  2004-01-17  28.9783333   \n",
       "4  AS a Marine 1st Lt. flying an FJ4B fighter/att...  2004-01-22  21.4180556   \n",
       "\n",
       "   longitude   \n",
       "0  -97.941111  \n",
       "1  -98.581082  \n",
       "2   -2.916667  \n",
       "3  -96.645833  \n",
       "4 -157.803611  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ddd4f46-f7a4-41a8-8288-d438bee22382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80332, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d54a9f-2298-4a49-b805-4c9abcac2297",
   "metadata": {},
   "source": [
    "# 1) Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd5bce5-4c0a-45b7-9600-cf4408b86e3a",
   "metadata": {},
   "source": [
    "## 1.1) Column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55368d5b-8e68-4b29-ae48-a049fa897c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'city', 'state', 'country', 'shape', 'duration (seconds)',\n",
       "       'duration (hours/min)', 'comments', 'date posted', 'latitude',\n",
       "       'longitude '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad450f24-dfbf-4865-b24f-2679711c54a1",
   "metadata": {},
   "source": [
    "We notice a first problem, that is, the 'longitude' column label is mispelled : it contains a blank space at the end of the string. Let's remove it in order to avoid further issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08b0f1bb-8d3d-4af9-9dd8-81136ac30d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns = {'longitude ': 'longitude'})\n",
    "#df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27913778-1bac-4a8b-acf1-af1b2622dee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime                 object\n",
       "city                     object\n",
       "state                    object\n",
       "country                  object\n",
       "shape                    object\n",
       "duration (seconds)       object\n",
       "duration (hours/min)     object\n",
       "comments                 object\n",
       "date posted              object\n",
       "latitude                 object\n",
       "longitude               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b42465-d58f-49e8-a227-b0e88a6e15bd",
   "metadata": {},
   "source": [
    "We also notice that 'longitude' column is a type float, which is pretty logical, whereas 'latitude' column if typed as an object : why ? Let's check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af5587e2-7172-4315-a491-15045b4ef5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration (seconds)</th>\n",
       "      <th>duration (hours/min)</th>\n",
       "      <th>comments</th>\n",
       "      <th>date posted</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43782</th>\n",
       "      <td>1974-05-22 05:30:00</td>\n",
       "      <td>mescalero indian reservation</td>\n",
       "      <td>nm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rectangle</td>\n",
       "      <td>180</td>\n",
       "      <td>two hours</td>\n",
       "      <td>Huge rectangular object emmitting intense whit...</td>\n",
       "      <td>2012-04-18</td>\n",
       "      <td>33q.200088</td>\n",
       "      <td>-105.624152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime                          city state country  \\\n",
       "43782  1974-05-22 05:30:00  mescalero indian reservation    nm     NaN   \n",
       "\n",
       "           shape duration (seconds) duration (hours/min)  \\\n",
       "43782  rectangle                180            two hours   \n",
       "\n",
       "                                                comments date posted  \\\n",
       "43782  Huge rectangular object emmitting intense whit...  2012-04-18   \n",
       "\n",
       "         latitude   longitude  \n",
       "43782  33q.200088 -105.624152  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['latitude'].astype(str).str.contains('[a-zA-Z]')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67706f7-3d1f-41ae-93b2-5f8d13ea4f4b",
   "metadata": {},
   "source": [
    "We see that this problem is probably due to a typo: the corresponding latitude for 'mescalero indian reservation' contains a letter ('q'). Since this issue only concerns a single row, we can check the real latitude of this place on the Internet (if there were too many rows, we would have chosen another soluton). It turns out that the real latitude is 33.2 so the error was indeed the result of a typo, so we can remove the misplaced letter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb8b9979-4283-4522-9cee-40b43cdb62a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['latitude'] = pd.to_numeric(df['latitude'].astype(str).str.extract('(\\d+.\\d+|\\d+)', expand = False))\n",
    "#df.dtypes #now both of the 'latitude' and 'longitude' columns have the right type!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8867a684-6f74-4f64-a704-2220dbcfc15b",
   "metadata": {},
   "source": [
    "## 1.2) Handling NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3075cc78-7826-4a73-8b61-fe43daa1c8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_na(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"Returns the sum and percentage of NaN values for each column of a given dataframe\"\"\"\n",
    "    \n",
    "    return pd.DataFrame({'sum': df.isna().sum(),\n",
    "                         'perc': df.isna().sum() * 100 / len(df)}).sort_values(by='perc',\n",
    "                                                                               ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdd68042-7569-4865-ab73-2b14310ec468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>9670</td>\n",
       "      <td>12.037544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>5797</td>\n",
       "      <td>7.216302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shape</th>\n",
       "      <td>1932</td>\n",
       "      <td>2.405019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comments</th>\n",
       "      <td>15</td>\n",
       "      <td>0.018673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration (seconds)</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration (hours/min)</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date posted</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       sum       perc\n",
       "country               9670  12.037544\n",
       "state                 5797   7.216302\n",
       "shape                 1932   2.405019\n",
       "comments                15   0.018673\n",
       "datetime                 0   0.000000\n",
       "city                     0   0.000000\n",
       "duration (seconds)       0   0.000000\n",
       "duration (hours/min)     0   0.000000\n",
       "date posted              0   0.000000\n",
       "latitude                 0   0.000000\n",
       "longitude                0   0.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_na(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dd4be0-9ed6-4d66-9903-07c2c25e5bb0",
   "metadata": {},
   "source": [
    "We notice that there are quite a lot of NaN values in both \"country\" and \"state\" columns. Let's see a few rows that are concerned by this phenomenon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01e63d5a-0db9-4066-994a-ab8b41a48e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration (seconds)</th>\n",
       "      <th>duration (hours/min)</th>\n",
       "      <th>comments</th>\n",
       "      <th>date posted</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949-10-10 21:00:00</td>\n",
       "      <td>lackland afb</td>\n",
       "      <td>tx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>light</td>\n",
       "      <td>7200</td>\n",
       "      <td>1-2 hrs</td>\n",
       "      <td>1949 Lackland AFB&amp;#44 TX.  Lights racing acros...</td>\n",
       "      <td>2005-12-16</td>\n",
       "      <td>29.384210</td>\n",
       "      <td>-98.581082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1955-10-10 17:00:00</td>\n",
       "      <td>chester (uk/england)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gb</td>\n",
       "      <td>circle</td>\n",
       "      <td>20</td>\n",
       "      <td>20 seconds</td>\n",
       "      <td>Green/Orange circular disc over Chester&amp;#44 En...</td>\n",
       "      <td>2008-01-21</td>\n",
       "      <td>53.200000</td>\n",
       "      <td>-2.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1965-10-10 21:00:00</td>\n",
       "      <td>penarth (uk/wales)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gb</td>\n",
       "      <td>circle</td>\n",
       "      <td>180</td>\n",
       "      <td>about 3 mins</td>\n",
       "      <td>penarth uk  circle  3mins  stayed 30ft above m...</td>\n",
       "      <td>2006-02-14</td>\n",
       "      <td>51.434722</td>\n",
       "      <td>-3.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1973-10-10 23:00:00</td>\n",
       "      <td>bermuda nas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>light</td>\n",
       "      <td>20</td>\n",
       "      <td>20 sec.</td>\n",
       "      <td>saw fast moving blip on the radar scope thin w...</td>\n",
       "      <td>2002-01-11</td>\n",
       "      <td>32.364167</td>\n",
       "      <td>-64.678611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1974-10-10 21:30:00</td>\n",
       "      <td>cardiff (uk/wales)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gb</td>\n",
       "      <td>disk</td>\n",
       "      <td>1200</td>\n",
       "      <td>20 minutes</td>\n",
       "      <td>back in 1974 I was 19 at the time and  lived i...</td>\n",
       "      <td>2007-02-01</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>-3.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80254</th>\n",
       "      <td>2009-09-09 21:15:00</td>\n",
       "      <td>nottinghamshire (uk/england)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gb</td>\n",
       "      <td>fireball</td>\n",
       "      <td>600.0</td>\n",
       "      <td>10 mins</td>\n",
       "      <td>resembled orange flame imagine a transparent h...</td>\n",
       "      <td>2009-12-12</td>\n",
       "      <td>53.166667</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80255</th>\n",
       "      <td>2009-09-09 21:38:00</td>\n",
       "      <td>kaiserlautern (germany)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>de</td>\n",
       "      <td>light</td>\n",
       "      <td>40.0</td>\n",
       "      <td>about 40 seconds</td>\n",
       "      <td>2 white lights over Kaiserslautern&amp;#44 ramstei...</td>\n",
       "      <td>2009-12-12</td>\n",
       "      <td>49.450000</td>\n",
       "      <td>7.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80319</th>\n",
       "      <td>2013-09-09 20:15:00</td>\n",
       "      <td>clifton</td>\n",
       "      <td>nj</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>~1hr+</td>\n",
       "      <td>Luminous line seen in New Jersey sky.</td>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>40.858433</td>\n",
       "      <td>-74.163755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80322</th>\n",
       "      <td>2013-09-09 21:00:00</td>\n",
       "      <td>aleksandrow (poland)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>light</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15 seconds</td>\n",
       "      <td>Two points of light following one another in a...</td>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>50.465843</td>\n",
       "      <td>22.891814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80324</th>\n",
       "      <td>2013-09-09 21:00:00</td>\n",
       "      <td>hamstead (hollyridge)</td>\n",
       "      <td>nc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>light</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2 minutes</td>\n",
       "      <td>8 to ten lights bright orange in color large t...</td>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>34.367594</td>\n",
       "      <td>-77.710548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12211 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime                          city state country  \\\n",
       "1      1949-10-10 21:00:00                  lackland afb    tx     NaN   \n",
       "2      1955-10-10 17:00:00          chester (uk/england)   NaN      gb   \n",
       "6      1965-10-10 21:00:00            penarth (uk/wales)   NaN      gb   \n",
       "18     1973-10-10 23:00:00                   bermuda nas   NaN     NaN   \n",
       "20     1974-10-10 21:30:00            cardiff (uk/wales)   NaN      gb   \n",
       "...                    ...                           ...   ...     ...   \n",
       "80254  2009-09-09 21:15:00  nottinghamshire (uk/england)   NaN      gb   \n",
       "80255  2009-09-09 21:38:00       kaiserlautern (germany)   NaN      de   \n",
       "80319  2013-09-09 20:15:00                       clifton    nj     NaN   \n",
       "80322  2013-09-09 21:00:00          aleksandrow (poland)   NaN     NaN   \n",
       "80324  2013-09-09 21:00:00         hamstead (hollyridge)    nc     NaN   \n",
       "\n",
       "          shape duration (seconds) duration (hours/min)  \\\n",
       "1         light               7200              1-2 hrs   \n",
       "2        circle                 20           20 seconds   \n",
       "6        circle                180         about 3 mins   \n",
       "18        light                 20              20 sec.   \n",
       "20         disk               1200           20 minutes   \n",
       "...         ...                ...                  ...   \n",
       "80254  fireball              600.0              10 mins   \n",
       "80255     light               40.0     about 40 seconds   \n",
       "80319     other             3600.0                ~1hr+   \n",
       "80322     light               15.0           15 seconds   \n",
       "80324     light              120.0            2 minutes   \n",
       "\n",
       "                                                comments date posted  \\\n",
       "1      1949 Lackland AFB&#44 TX.  Lights racing acros...  2005-12-16   \n",
       "2      Green/Orange circular disc over Chester&#44 En...  2008-01-21   \n",
       "6      penarth uk  circle  3mins  stayed 30ft above m...  2006-02-14   \n",
       "18     saw fast moving blip on the radar scope thin w...  2002-01-11   \n",
       "20     back in 1974 I was 19 at the time and  lived i...  2007-02-01   \n",
       "...                                                  ...         ...   \n",
       "80254  resembled orange flame imagine a transparent h...  2009-12-12   \n",
       "80255  2 white lights over Kaiserslautern&#44 ramstei...  2009-12-12   \n",
       "80319              Luminous line seen in New Jersey sky.  2013-09-30   \n",
       "80322  Two points of light following one another in a...  2013-09-30   \n",
       "80324  8 to ten lights bright orange in color large t...  2013-09-30   \n",
       "\n",
       "        latitude  longitude  \n",
       "1      29.384210 -98.581082  \n",
       "2      53.200000  -2.916667  \n",
       "6      51.434722  -3.180000  \n",
       "18     32.364167 -64.678611  \n",
       "20     51.500000  -3.200000  \n",
       "...          ...        ...  \n",
       "80254  53.166667  -1.000000  \n",
       "80255  49.450000   7.750000  \n",
       "80319  40.858433 -74.163755  \n",
       "80322  50.465843  22.891814  \n",
       "80324  34.367594 -77.710548  \n",
       "\n",
       "[12211 rows x 11 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('country.isna() | state.isna()', engine = 'python')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110ba804-c01f-43db-a4f0-24a5214e654a",
   "metadata": {},
   "source": [
    "* For the \"state\" column, the problem is likely due to the fact that a \"state\" is commonly used in the US or in Canada, but not in other countries. Thus, we won't touch at this column for the moment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b661831-3f0c-4239-a35b-d2a4812ce857",
   "metadata": {},
   "source": [
    "### 1.2.1 Cleaning \"country\" column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ccdd7d-3625-4cea-b96a-aef33c0a0a92",
   "metadata": {},
   "source": [
    "In a first approach, we decided to fill NaN values in the \"country\" column by searching the corresponding country of the given latitude and longitude (this two columns are always filled). To do so, we will use the \"geopy\" library (geopy is actually a client), which allows to find the country, based on the geographic coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24ece5b8-030b-4afe-bc77-7ae487b3d019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the service\n",
    "geolocator = Nominatim(user_agent=\"begining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27e4ae95-1c5c-4d09-90ce-88f471d38430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partioning our df between missing values and non-missing values\n",
    "df1 = df[df['country'].isna()].reset_index(drop=False)\n",
    "df2 = df[~df['country'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc575d32-8d92-4f90-acec-e9094485b70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape[0] + df2.shape[0] == df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edaaafcb-4cfb-43bd-b089-4070ca62a02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_point(lat: float,lon: float):\n",
    "    \n",
    "    \"\"\"Transforms the given latitude and longitude into a coordinate system (use Point method\n",
    "    from geopy\"\"\"\n",
    "    \n",
    "    return Point(lat, lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e438a8e7-c576-4cad-9f20-6b225c1b7ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a full coordinate system for each row, based on the latitude and longitude column\n",
    "df1['coords'] = [to_point(x, y) for x, y in zip(df1['latitude'], df1['longitude'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "193038d9-6f7a-4571-ae9c-17a346c3eba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geo_feature(coord, feature: str):\n",
    "    \n",
    "    \"\"\"Get the desired feature from a given geographic coordinate (e.g.,\n",
    "    country name, country code, etc: please refers to the geopy doc for more informations)\"\"\"\n",
    "    \n",
    "    try:\n",
    "        location = geolocator.reverse(coord)\n",
    "        return location.raw['address'][feature]\n",
    "    \n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53795ed9-c54c-42af-903d-20fe8eb6b69d",
   "metadata": {},
   "source": [
    "We will apply our functions \"get_geo_feature\" to obtain the country code for each row where the country is missing. **This step might be time costly (approx. 1h30).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab1355a2-f807-48c4-a901-3867e871d58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['country'] = np.vectorize(get_geo_feature)(df1['coords'].values, 'country_code').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07f96590-f833-498f-941a-7fc008387380",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['country'] = np.where(df1['country']=='nan', np.nan, df1['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b3976af-c8ba-4278-8bdc-1e90e886c8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "592"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['country'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec263a03-b694-4a3b-a5ac-ec83cf4e695b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop(['coords', 'index'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1d297a-9c3e-4477-8eba-202939537944",
   "metadata": {},
   "source": [
    "The observations where the country was (formerly) missing must be combined with those where the country was known. Thus, we have to binds the rows of the two dataframes in order to get al the observations reunited:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6573cd2-d8e8-45b0-873f-7dc56a378395",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2], ignore_index=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c29f6a9-1897-432a-b37e-10193dc5cfd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80332, 11)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # we got back the shape of the begnining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ad8413-982d-4f84-a253-731a48713805",
   "metadata": {},
   "source": [
    "In a second approach, we will use the information that we have in the \"city\" column: indeed we notice that there is some potential information about the country inside this column (see above)!! But sometimes, this information is not relevant, for example if we look at the tail of the dataframe above, \"hollyridge\" is clearny not a country, but a US state! We have to make sure that if there is additionnal information in the \"city\", this information is actually a country!\n",
    "\n",
    "The easiest way to do this is to use web-scraping to get the list of all countries with the corresponding country codes (country codes will be useful to standardize the country column):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff5cadc6-861d-4f76-a737-af7bf6127e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the parser\n",
    "URL = \"https://www.iban.com/country-codes\"\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35f6a4db-1eba-4b2f-b10b-788680b00136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['table', 'table-bordered', 'downloads', 'tablesorter']\n"
     ]
    }
   ],
   "source": [
    "for table in soup.find_all('table'):\n",
    "    print(table.get('class'))\n",
    "    \n",
    "table = soup.find('table', class_='table table-bordered downloads tablesorter')\n",
    "#print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f914729d-bf4d-43ec-bd88-5e764397f503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Alpha-2 code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afghanistan</td>\n",
       "      <td>af</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>åland islands</td>\n",
       "      <td>ax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>albania</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>algeria</td>\n",
       "      <td>dz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>american samoa</td>\n",
       "      <td>as</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Country Alpha-2 code\n",
       "0     afghanistan           af\n",
       "1   åland islands           ax\n",
       "2         albania           al\n",
       "3         algeria           dz\n",
       "4  american samoa           as"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "countries_id = pd.DataFrame(columns=['Country', 'Alpha-2 code'])\n",
    "              \n",
    "# collecting country names and country codes\n",
    "for row in table.tbody.find_all('tr'):\n",
    "     # STEPS FOR ONE ROW :\n",
    "    \n",
    "    # find all data for each column\n",
    "    columns = row.find_all('td')\n",
    "    \n",
    "    # if the row is not empty, we get the 2 informations that we want, ie country and alpha-2 code\n",
    "    if(columns != []):\n",
    "        country = columns[0].text.strip().lower()\n",
    "        alpha_2_code = columns[1].text.strip().lower()\n",
    "        \n",
    "        # then, we merge this 2 informations together\n",
    "        df_to_append = pd.DataFrame({'Country': country,\n",
    "                                     'Alpha-2 code': alpha_2_code},\n",
    "                                   index=[0])\n",
    "        \n",
    "        # and finally append to the \"main\" dataframe\n",
    "        countries_id = pd.concat([countries_id, df_to_append], ignore_index=True)\n",
    "        \n",
    "print(countries_id.shape)\n",
    "display(countries_id.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31d037f-756b-45ed-8fcf-8bcc559074fd",
   "metadata": {},
   "source": [
    "Now that we have a list of all the countries in the world, we can first standardize the country column by converting the country codes into country names, for non-missing country values in our dataframe. To do so, we just have to create a dictionnary with both the country-code and the corresponding country name, and then map it to the \"country\" column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45171cd9-b3fe-4ff2-9392-43b743d95161",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_dict = dict(zip(countries_id['Alpha-2 code'], countries_id['Country']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7955bb5b-b501-42d0-8cbd-a6554ad84a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['country'] = df['country'].replace(countries_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4e481b-bacf-4685-a4c1-0540667b096c",
   "metadata": {},
   "source": [
    "Finally, we can easily detect if there is some informative content in the \"city\" column for each row, by comparing it  with the list of the countries that we previously built. In order to perform this step, we will have to use regex: first, we create a \"large pattern\" with our country Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1c3caa27-f766-404f-b04f-16dd5fedd2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_countries = '('+ '|'.join(countries_id['Country'].apply(lambda x: re.sub(r'\\((.*)\\)', '', x))) +')'\n",
    "#pattern_countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e96808-911e-4f61-96e5-3f47edc63ce3",
   "metadata": {},
   "source": [
    "Then, we match this pattern with the \"city\" column, for each row (NB: str.extract method is vectorized):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea6b22c3-efd8-4cb3-99bc-dd3ee9a77f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['test'] = df['city'].str.extract(pattern_countries)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bee22c5f-b7ee-4442-b17d-e4964970f027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "592"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.country.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eb5e64-1440-4f4c-bf17-3a347d023ce4",
   "metadata": {},
   "source": [
    "Then, we can replace the values of the country that are missing by the values obtained with our method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "28650c2a-9149-4f3c-bdee-3be2b39e2205",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['country'] = np.where(df['country'].isna(), df['test'], df['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5988442f-5e52-4bb8-8e87-71fd76cbef8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199, 12)\n",
      "(73154, 12)\n",
      "(199, 12)\n"
     ]
    }
   ],
   "source": [
    "print(df[df['country'].isna()].shape)\n",
    "print(df[df['test'].isna()].shape)\n",
    "print(df[df['country'].isna() & df['test'].isna()].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facc6557-9c15-42cf-b3fc-14a4193cfd39",
   "metadata": {},
   "source": [
    "We see that our method allowed to reduce the number of NaN values in the \"country\" column. But there is still some missing values: let's check those rows to see the issue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "39b5fba9-f17a-4ca4-bd3e-ca88a40a6de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arkansas (eastern; on us hwy 70 abt 75 m w/o memphis&#44 tn)     1\n",
      "arkansas (while driving)                                         1\n",
      "armidale (australi)                                              1\n",
      "atlantic ocean                                                  11\n",
      "atlantic ocean (at sea)                                          1\n",
      "atlantic ocean (between nassau&#44 bahamas&#44 and florida)      1\n",
      "atlantic ocean (between san juan and u.s. virgin isl.)           1\n",
      "atlantic ocean (cv-67 u.s.navy)                                  1\n",
      "atlantic ocean (in flight)                                       2\n",
      "atlantic ocean (inflight)                                        1\n",
      "atlantic ocean (mid-atlantic)                                    1\n",
      "atlantic ocean (middle)                                          1\n",
      "atlantic ocean (nc/250+nm off the coast)                         1\n",
      "atlantic ocean (off africa)                                      1\n",
      "atlantic ocean (on cruise ship)                                  1\n",
      "atlantic ocean (troopship/ uss rose)                             1\n",
      "atlantic ocean (virgin islands)                                  1\n",
      "barstow-baker                                                    1\n",
      "beaver lake                                                      1\n",
      "beaverton/tigard                                                 1\n",
      "betetourt county                                                 1\n",
      "big bear                                                         1\n",
      "blackburn&#44 lancashire (uk/england)                            1\n",
      "bogor                                                            1\n",
      "boston&#44 lincolnshire (uk/england)                             1\n",
      "boulder city                                                     1\n",
      "broadelbin                                                       1\n",
      "broken hill                                                      1\n",
      "caicara (venezuela)                                              1\n",
      "cape may courthouse                                              1\n",
      "cape town                                                        1\n",
      "caribbean sea                                                    4\n",
      "caribbean sea (u.s. navy ship)                                   2\n",
      "caribbean sea (uss w.s. sims)                                    1\n",
      "caribbean sea (venezuela)                                        1\n",
      "caspian sea (south of) (iran)                                    1\n",
      "cedar point/emerald isle/swansboro                               1\n",
      "celta                                                            1\n",
      "chawton&#44 hampshire (uk/england)                               1\n",
      "clear creek east resort                                          1\n",
      "cochabamba (bolivia)                                             3\n",
      "collins/prentis                                                  1\n",
      "commerce township                                                1\n",
      "coventry area (uk/england)                                       1\n",
      "cuijk (netherlands)                                              1\n",
      "darley (australi)                                                1\n",
      "dateland (just before                                            1\n",
      "dells (north  of)                                                1\n",
      "dennisport                                                       1\n",
      "east atlantic ocean                                              1\n",
      "eldorado                                                         2\n",
      "elizabeth township                                               1\n",
      "enschede&#44 overijssel (netherlands)                            1\n",
      "europe                                                           1\n",
      "federal way/redondo                                              1\n",
      "forth estuary (edinburgh) (uk/scotland)                          1\n",
      "franconia notch (i-93 southbound)                                1\n",
      "franklin/brentwood                                               1\n",
      "galloway                                                         1\n",
      "gila bend- yuma?                                                 1\n",
      "greenbried                                                       1\n",
      "guayaquil                                                        1\n",
      "harison                                                          1\n",
      "harrison twp.                                                    1\n",
      "hattiesburg/columbia (between)                                   1\n",
      "henderson/las vegas                                              1\n",
      "highway 78 between bailey &amp; bonham&#44 texas                 1\n",
      "iloilo (philippines)                                             1\n",
      "inside passage                                                   1\n",
      "interstate 75 (between mile markers 270 &amp; 276)               1\n",
      "iowa (unspecified location)                                      1\n",
      "ipatinga (minas gerais) (brasil)                                 1\n",
      "iron moutain                                                     1\n",
      "jakarta-tokyo (inflight)                                         1\n",
      "jax beach                                                        1\n",
      "joan&oacute;polis (brasil)                                       1\n",
      "jupiter farms                                                    1\n",
      "kentucky (rural)                                                 1\n",
      "kerkrade (netherlands)                                           1\n",
      "kingwood                                                         1\n",
      "la paz (bolivia)                                                 2\n",
      "la paz/cochabamba/potosi                                         1\n",
      "laude                                                            1\n",
      "lelystad (netherlands)                                           1\n",
      "lenior city                                                      1\n",
      "leroy                                                            1\n",
      "lompoc/vandenberg afb                                            1\n",
      "lowestoft (uk/england)                                           1\n",
      "lytham st. annes (uk/england)                                    1\n",
      "maceio (brasil)                                                  1\n",
      "magnolia township                                                1\n",
      "marinette/menominee                                              1\n",
      "mcdermott                                                        1\n",
      "mediterranean sea                                                2\n",
      "mediterranean sea (in flight)                                    1\n",
      "monterey/seaside                                                 1\n",
      "monterrico (guatamala)                                           1\n",
      "multnomah village                                                1\n",
      "mussel shoals                                                    1\n",
      "newcastle-upon-tyne (uk/england)                                 1\n",
      "north atlantic ocean                                             1\n",
      "north atlanticocean                                              1\n",
      "north shore oahu                                                 1\n",
      "ocean isle                                                       2\n",
      "pacific ocean                                                    3\n",
      "pacific ocean (1500mi.sw of u.s.mainland)                        1\n",
      "pacific ocean (approx. 250 mi. over)                             1\n",
      "pacific ocean (in-flight sighting)                               1\n",
      "pacific ocean (in-flight; from tokyo airport to honolulu)        1\n",
      "pacific ocean (near california coast)                            1\n",
      "pacific ocean (near huntington beach)                            1\n",
      "pacific ocean (no state)                                         1\n",
      "pacific ocean (western)                                          1\n",
      "palmerston north                                                 1\n",
      "paraparaumu                                                      1\n",
      "persian gulf                                                     1\n",
      "philippine sea (at sea)                                          1\n",
      "phoenix/oswego                                                   1\n",
      "piedra blanka (los padres national forest)                       1\n",
      "pinnacles national monument                                      1\n",
      "piscataquis county                                               1\n",
      "polzeth (uk/england)                                             1\n",
      "pompano/deerfield beach                                          1\n",
      "poole&#44 dorset (uk/england)                                    1\n",
      "port jeff station                                                1\n",
      "prescott                                                         1\n",
      "puget sound (aboard ferry boat)                                  1\n",
      "rayleigh  essex  (uk/england)                                    1\n",
      "remote                                                           1\n",
      "river falls/prescott (between)                                   1\n",
      "rochester hill                                                   1\n",
      "rockaway                                                         1\n",
      "rocking chair mtn/sedona                                         1\n",
      "rocky mountain national park                                     1\n",
      "rotterdam (netherlands)                                          1\n",
      "s&atilde;o paulo (brasil)                                        1\n",
      "s. charleston                                                    1\n",
      "san deigo                                                        1\n",
      "sandy                                                            2\n",
      "santiago                                                         1\n",
      "sao paulo (brasil)                                               1\n",
      "saquarema (rio de janeiro) (brasil)                              1\n",
      "sarajevo (bosnia)                                                1\n",
      "sarajevo (bosnia/herzegovina)                                    1\n",
      "scott city/chaffe (on hwy. m)                                    1\n",
      "sedro woolley                                                    1\n",
      "severa park                                                      1\n",
      "shafter                                                          1\n",
      "shelby twp                                                       1\n",
      "sneads/chattahoochee                                             1\n",
      "soest (netherlands)                                              1\n",
      "south ontario                                                    1\n",
      "split                                                            1\n",
      "staten island                                                    2\n",
      "success                                                          1\n",
      "sun city summerlin                                               1\n",
      "surry co.                                                        1\n",
      "swindon/didcott (uk/england)                                     1\n",
      "tacoma/spanway                                                   1\n",
      "thornbury&#44 bristol uk (england)                               1\n",
      "tirau                                                            1\n",
      "tyrrhenian sea                                                   1\n",
      "united states                                                    1\n",
      "utrecht (netherlands)                                            1\n",
      "vashon island                                                    1\n",
      "wading river? franklin sq                                        1\n",
      "washington&#44 d.c.                                              3\n",
      "waynesborough                                                    1\n",
      "west haven                                                       1\n",
      "westlake village                                                 1\n",
      "wickliff                                                         1\n",
      "yarmouthport                                                     1\n",
      "Name: city, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "print(df[df['test'].isna() & df['country'].isna()]['city'].value_counts().sort_index())\n",
    "\n",
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4fdc63-f680-4a76-b132-4fd58c18d6df",
   "metadata": {},
   "source": [
    "We notice 2 main issues:\n",
    "* the \"city\" column may contain a sea or ocean name. For these rows, we are going to define the country as \"sea\" or \"ocean\";\n",
    "* there is some issues with country names such as \"brazil\", \"bolivia\", \"australia\". For what is possible and easy, we will replace the country names by hand. But for the remaining rows (there aren't many), we will put a NaN value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "632cae6a-3997-4ea9-a4ad-5b5cfb06f462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_exceptions(row: str) -> str or float:\n",
    "    \n",
    "    \"\"\"This function was made to be applied to a single dataframe string column. Return either 'ocean',\n",
    "    'sea', or a predefined country name.\"\"\"\n",
    "    \n",
    "    if re.search(r\"ocean|sea\", row):\n",
    "        return re.findall(r'ocean|sea', row)[0]\n",
    "    \n",
    "    elif re.search(r\"brasil\", row):\n",
    "        return \"brazil\"\n",
    "    \n",
    "    elif re.search(r\"uk/england\", row):\n",
    "        return \"united kingdom of great britain and northern ireland (the)\"\n",
    "    \n",
    "    elif re.search(r\"netherlands\", row):\n",
    "        return \"netherlands (the)\"\n",
    "    \n",
    "    elif re.search(r\"bolivia\", row):\n",
    "        return \"bolivia (plurinational state of)\"\n",
    "    \n",
    "    elif re.search(r\"australi\", row):\n",
    "        return \"australia\"\n",
    "    \n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "#pbb['test'] = pbb['city'].apply(replace_exceptions)\n",
    "#pbb[pbb['test'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "601f2d99-0a6f-4fca-8559-570ce068b0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199, 13)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['country'].isna())].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1ac43ced-5570-49f8-b52c-42cba803d9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['country'] = np.where((df['test'].isna() & df['country'].isna()), df['city'].apply(replace_exceptions), df['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ee173ffe-8692-4586-bb34-a9861687487f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 13)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['country'].isna())].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a84fce3-806c-42b2-8a5c-dc315c5ba7af",
   "metadata": {},
   "source": [
    "For the country name that are still missing, we decided to delete them, because they are very few of them, we decided to let them as NaN values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f65628-552c-4766-8779-43eedc547f96",
   "metadata": {},
   "source": [
    "## 1.3) Cleaning 'city' column\n",
    "\n",
    "If we have a closer look to this column, we see that the values are not harmonized and can be confusing and noisy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8007317f-28a3-4d45-9807-cbbd412ff96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration (seconds)</th>\n",
       "      <th>duration (hours/min)</th>\n",
       "      <th>comments</th>\n",
       "      <th>date posted</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>test</th>\n",
       "      <th>test2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1979-10-10 22:00:00</td>\n",
       "      <td>saddle lake (canada)</td>\n",
       "      <td>ab</td>\n",
       "      <td>canada</td>\n",
       "      <td>triangle</td>\n",
       "      <td>270</td>\n",
       "      <td>4.5 or more min.</td>\n",
       "      <td>Lights far above&amp;#44  that glance; then flee f...</td>\n",
       "      <td>2005-01-19</td>\n",
       "      <td>53.970571</td>\n",
       "      <td>-111.689885</td>\n",
       "      <td>canada</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1982-10-10 07:00:00</td>\n",
       "      <td>gisborne (new zealand)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>new zealand</td>\n",
       "      <td>disk</td>\n",
       "      <td>120</td>\n",
       "      <td>2min</td>\n",
       "      <td>gisborne nz 1982 wainui beach to sponge bay</td>\n",
       "      <td>2002-01-11</td>\n",
       "      <td>38.662334</td>\n",
       "      <td>178.017649</td>\n",
       "      <td>new zealand</td>\n",
       "      <td>new zealand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1993-10-10 03:00:00</td>\n",
       "      <td>zlatoust (russia)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>russian federation (the)</td>\n",
       "      <td>sphere</td>\n",
       "      <td>1200</td>\n",
       "      <td>20 minutes</td>\n",
       "      <td>I woke up at night and looked out the window n...</td>\n",
       "      <td>2004-12-14</td>\n",
       "      <td>55.183333</td>\n",
       "      <td>59.650000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>russian federation (the)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1996-10-10 20:00:00</td>\n",
       "      <td>lake macquarie (nsw&amp;#44 australia)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>australia</td>\n",
       "      <td>light</td>\n",
       "      <td>300</td>\n",
       "      <td>5 min</td>\n",
       "      <td>RED LIGHT WITH OTHER RED FLASHING LIGHT&amp;#44 ON...</td>\n",
       "      <td>1999-05-24</td>\n",
       "      <td>33.093373</td>\n",
       "      <td>151.588982</td>\n",
       "      <td>australia</td>\n",
       "      <td>australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1999-10-10 22:30:00</td>\n",
       "      <td>casey key (north end of)</td>\n",
       "      <td>fl</td>\n",
       "      <td>united states of america (the)</td>\n",
       "      <td>triangle</td>\n",
       "      <td>120</td>\n",
       "      <td>several minutes</td>\n",
       "      <td>A large trianglual shaped craft flew from hori...</td>\n",
       "      <td>2002-09-19</td>\n",
       "      <td>27.150053</td>\n",
       "      <td>-82.480653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>united states of america (the)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80298</th>\n",
       "      <td>2012-09-09 14:00:00</td>\n",
       "      <td>pictou (canada)</td>\n",
       "      <td>ns</td>\n",
       "      <td>canada</td>\n",
       "      <td>disk</td>\n",
       "      <td>600.0</td>\n",
       "      <td>10 minutes</td>\n",
       "      <td>Spotted a object over the town&amp;#39s business d...</td>\n",
       "      <td>2012-09-24</td>\n",
       "      <td>45.666667</td>\n",
       "      <td>-62.700000</td>\n",
       "      <td>canada</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80311</th>\n",
       "      <td>2012-09-09 21:00:00</td>\n",
       "      <td>new york city (brooklyn)</td>\n",
       "      <td>ny</td>\n",
       "      <td>united states of america (the)</td>\n",
       "      <td>light</td>\n",
       "      <td>1290.0</td>\n",
       "      <td>21:30</td>\n",
       "      <td>Glowing&amp;#44 circular lights visible in the clo...</td>\n",
       "      <td>2012-09-24</td>\n",
       "      <td>40.714167</td>\n",
       "      <td>-74.006389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>united states of america (the)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80317</th>\n",
       "      <td>2013-09-09 01:50:00</td>\n",
       "      <td>buffalo (west of; on highway 90 west)</td>\n",
       "      <td>ny</td>\n",
       "      <td>united states of america (the)</td>\n",
       "      <td>triangle</td>\n",
       "      <td>180.0</td>\n",
       "      <td>3 minutes</td>\n",
       "      <td>Massive Flat Black triangle  with 3 red lights.</td>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>42.886389</td>\n",
       "      <td>-78.878611</td>\n",
       "      <td>NaN</td>\n",
       "      <td>united states of america (the)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80321</th>\n",
       "      <td>2013-09-09 13:10:00</td>\n",
       "      <td>calmar (canada)</td>\n",
       "      <td>ab</td>\n",
       "      <td>canada</td>\n",
       "      <td>unknown</td>\n",
       "      <td>90.0</td>\n",
       "      <td>45-90 seconds</td>\n",
       "      <td>Fastest dot I have ever seen in the sky&amp;#33</td>\n",
       "      <td>2013-09-09</td>\n",
       "      <td>53.250000</td>\n",
       "      <td>-113.783333</td>\n",
       "      <td>canada</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80325</th>\n",
       "      <td>2013-09-09 21:00:00</td>\n",
       "      <td>milton (canada)</td>\n",
       "      <td>on</td>\n",
       "      <td>canada</td>\n",
       "      <td>fireball</td>\n",
       "      <td>180.0</td>\n",
       "      <td>3 minutes</td>\n",
       "      <td>Massive Bright Orange Fireball in Sky</td>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>46.300000</td>\n",
       "      <td>-63.216667</td>\n",
       "      <td>canada</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12466 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime                                   city state  \\\n",
       "2      1979-10-10 22:00:00                   saddle lake (canada)    ab   \n",
       "3      1982-10-10 07:00:00                 gisborne (new zealand)   NaN   \n",
       "6      1993-10-10 03:00:00                      zlatoust (russia)   NaN   \n",
       "8      1996-10-10 20:00:00     lake macquarie (nsw&#44 australia)   NaN   \n",
       "10     1999-10-10 22:30:00               casey key (north end of)    fl   \n",
       "...                    ...                                    ...   ...   \n",
       "80298  2012-09-09 14:00:00                        pictou (canada)    ns   \n",
       "80311  2012-09-09 21:00:00               new york city (brooklyn)    ny   \n",
       "80317  2013-09-09 01:50:00  buffalo (west of; on highway 90 west)    ny   \n",
       "80321  2013-09-09 13:10:00                        calmar (canada)    ab   \n",
       "80325  2013-09-09 21:00:00                        milton (canada)    on   \n",
       "\n",
       "                              country     shape duration (seconds)  \\\n",
       "2                              canada  triangle                270   \n",
       "3                         new zealand      disk                120   \n",
       "6            russian federation (the)    sphere               1200   \n",
       "8                           australia     light                300   \n",
       "10     united states of america (the)  triangle                120   \n",
       "...                               ...       ...                ...   \n",
       "80298                          canada      disk              600.0   \n",
       "80311  united states of america (the)     light             1290.0   \n",
       "80317  united states of america (the)  triangle              180.0   \n",
       "80321                          canada   unknown               90.0   \n",
       "80325                          canada  fireball              180.0   \n",
       "\n",
       "      duration (hours/min)                                           comments  \\\n",
       "2         4.5 or more min.  Lights far above&#44  that glance; then flee f...   \n",
       "3                     2min        gisborne nz 1982 wainui beach to sponge bay   \n",
       "6               20 minutes  I woke up at night and looked out the window n...   \n",
       "8                    5 min  RED LIGHT WITH OTHER RED FLASHING LIGHT&#44 ON...   \n",
       "10         several minutes  A large trianglual shaped craft flew from hori...   \n",
       "...                    ...                                                ...   \n",
       "80298           10 minutes  Spotted a object over the town&#39s business d...   \n",
       "80311                21:30  Glowing&#44 circular lights visible in the clo...   \n",
       "80317            3 minutes    Massive Flat Black triangle  with 3 red lights.   \n",
       "80321        45-90 seconds        Fastest dot I have ever seen in the sky&#33   \n",
       "80325            3 minutes              Massive Bright Orange Fireball in Sky   \n",
       "\n",
       "      date posted   latitude   longitude         test  \\\n",
       "2      2005-01-19  53.970571 -111.689885       canada   \n",
       "3      2002-01-11  38.662334  178.017649  new zealand   \n",
       "6      2004-12-14  55.183333   59.650000          NaN   \n",
       "8      1999-05-24  33.093373  151.588982    australia   \n",
       "10     2002-09-19  27.150053  -82.480653          NaN   \n",
       "...           ...        ...         ...          ...   \n",
       "80298  2012-09-24  45.666667  -62.700000       canada   \n",
       "80311  2012-09-24  40.714167  -74.006389          NaN   \n",
       "80317  2013-09-30  42.886389  -78.878611          NaN   \n",
       "80321  2013-09-09  53.250000 -113.783333       canada   \n",
       "80325  2013-09-30  46.300000  -63.216667       canada   \n",
       "\n",
       "                                test2  \n",
       "2                              canada  \n",
       "3                         new zealand  \n",
       "6            russian federation (the)  \n",
       "8                           australia  \n",
       "10     united states of america (the)  \n",
       "...                               ...  \n",
       "80298                          canada  \n",
       "80311  united states of america (the)  \n",
       "80317  united states of america (the)  \n",
       "80321                          canada  \n",
       "80325                          canada  \n",
       "\n",
       "[12466 rows x 13 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query(\"city.str.contains('\\(') | city.str.contains('\\)')\", engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69ce709-d20e-4426-baf2-cce44c202179",
   "metadata": {},
   "source": [
    "We have to remove all parenthesis from this column. Then, we have to harmonize the city name; and we will eventually standardize this column by capitalizing the city names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9aabba7f-3d8d-4793-af3f-7bf4492fabb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_city_unique():\n",
    "    return print(len(set(df['city'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "13dc525e-2c05-4e1e-9371-f950c00c2226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_city_col(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    print_city_unique()\n",
    "    \n",
    "    # removing parentheses and their content for the column \"city\"\n",
    "    df['city'] = df['city'].str.replace(r\"\\(.*\\)\",\"\", regex=True)\n",
    "    print_city_unique()\n",
    "    \n",
    "    # removing non-alphanumeric characters from the strings for the column \"city\", including numbers\n",
    "    df['city'] = [re.sub('[^\\w\\s]|\\d+', '', x) for x in df['city']]\n",
    "    print_city_unique()\n",
    "    \n",
    "    # turning the first letter of each city name into a capital letter\n",
    "    df['city'] = df['city'].str.title()\n",
    "    print_city_unique()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "01868c35-355a-457e-9149-2c3b38f2b576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19900\n",
      "18386\n",
      "18290\n",
      "18290\n"
     ]
    }
   ],
   "source": [
    "df = clean_city_col(df)\n",
    "# the number of differents city values at each step of the processing is decreasing: perfect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e54d0d-7b64-43ec-949b-f051900be69b",
   "metadata": {},
   "source": [
    "Our processing of the city column has resulted in the harmonization and standardization of city names. This achievement will be very convenient for the interactive map that we are going to create and also for an in-depth statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ef1d2e77-d39f-44a0-8270-f7bfe2908a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['test', 'test2'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cce6b27-2941-47b6-a2f9-dd9bd1ce5b4c",
   "metadata": {},
   "source": [
    "## 1.4) Cleaning \"shape\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "80bb292d-af67-46b0-87e9-71f5a4890fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "light        16565\n",
       "triangle      7865\n",
       "circle        7608\n",
       "fireball      6208\n",
       "other         5649\n",
       "unknown       5584\n",
       "sphere        5387\n",
       "disk          5213\n",
       "oval          3733\n",
       "formation     2457\n",
       "cigar         2057\n",
       "changing      1962\n",
       "flash         1328\n",
       "rectangle     1297\n",
       "cylinder      1283\n",
       "diamond       1178\n",
       "chevron        952\n",
       "egg            759\n",
       "teardrop       750\n",
       "cone           316\n",
       "cross          233\n",
       "delta            7\n",
       "crescent         2\n",
       "round            2\n",
       "dome             1\n",
       "pyramid          1\n",
       "flare            1\n",
       "hexagon          1\n",
       "changed          1\n",
       "Name: shape, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"shape\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93df55e5-f331-4893-89d5-d9b1de81ad7a",
   "metadata": {},
   "source": [
    "## next###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f052e2c-b37e-4f38-ba31-0f43defe94f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46302    2014-05-08 18:45:00\n",
       "46301    2014-05-08 00:00:00\n",
       "46155    2014-05-07 23:30:00\n",
       "46154    2014-05-07 21:20:00\n",
       "46153    2014-05-07 21:10:00\n",
       "                ...         \n",
       "46694    1920-06-11 21:00:00\n",
       "40275    1916-04-05 13:00:00\n",
       "46858    1910-06-01 15:00:00\n",
       "10580    1910-01-02 00:00:00\n",
       "7863     1906-11-11 00:00:00\n",
       "Name: datetime, Length: 80332, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"datetime\"].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e46cc4a2-28fb-4e52-873f-3677b43f8b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    This event took place in early fall around 194...\n",
       "1    1949 Lackland AFB&#44 TX.  Lights racing acros...\n",
       "2    Green/Orange circular disc over Chester&#44 En...\n",
       "3    My older brother and twin sister were leaving ...\n",
       "4    AS a Marine 1st Lt. flying an FJ4B fighter/att...\n",
       "Name: comments, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"comments\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504519c4-80ea-4427-bffb-e5d84bead0d2",
   "metadata": {},
   "source": [
    "# 2) Data Exportation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "09384fa3-56ea-44bb-ad1f-e5b42f695416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>5797</td>\n",
       "      <td>7.216302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shape</th>\n",
       "      <td>1932</td>\n",
       "      <td>2.405019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>112</td>\n",
       "      <td>0.139421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comments</th>\n",
       "      <td>15</td>\n",
       "      <td>0.018673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration (seconds)</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration (hours/min)</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date posted</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       sum      perc\n",
       "state                 5797  7.216302\n",
       "shape                 1932  2.405019\n",
       "country                112  0.139421\n",
       "comments                15  0.018673\n",
       "datetime                 0  0.000000\n",
       "city                     0  0.000000\n",
       "duration (seconds)       0  0.000000\n",
       "duration (hours/min)     0  0.000000\n",
       "date posted              0  0.000000\n",
       "latitude                 0  0.000000\n",
       "longitude                0  0.000000"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_na(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6059cce0-55e0-4b3b-beef-9aa8069f68ed",
   "metadata": {},
   "source": [
    "Since we have clean our data, we should export it into a new .csv file, so as to facilitate oru collaborative work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "b3f10994-3af7-4b3e-8f16-9b82c950b56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/ufo_sightings_clean.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
