{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dc8a077-80c0-479d-8970-3f7cc10668e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from geopy.point import Point\n",
    "from geopy.geocoders import Nominatim\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "58fc22e5-ef59-41eb-809c-d5360b393bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also importing functions from our module\n",
    "from functions_cleaning import count_na, to_point, get_geo_feature, replace_exceptions, print_city_unique, clean_city_col, get_table_bs4, alpha_code_reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5524be1c-f2b1-4435-b598-e93097a145ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jbrable/Documents/ENSAE_2AD/S1/python/UFO'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "809322fd-23b5-4d60-ae85-16f524114b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j3/7p5c8ygd7yg6bgkb6r90ddhm0000gn/T/ipykernel_34177/2315484744.py:1: DtypeWarning: Columns (5,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"data/ufo_sightings_scrubbed.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/ufo_sightings_scrubbed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e31feccc-eefd-4683-9f74-6df01f2b388c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration (seconds)</th>\n",
       "      <th>duration (hours/min)</th>\n",
       "      <th>comments</th>\n",
       "      <th>date posted</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949-10-10 20:30:00</td>\n",
       "      <td>san marcos</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>cylinder</td>\n",
       "      <td>2700</td>\n",
       "      <td>45 minutes</td>\n",
       "      <td>This event took place in early fall around 194...</td>\n",
       "      <td>2004-04-27</td>\n",
       "      <td>29.8830556</td>\n",
       "      <td>-97.941111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949-10-10 21:00:00</td>\n",
       "      <td>lackland afb</td>\n",
       "      <td>tx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>light</td>\n",
       "      <td>7200</td>\n",
       "      <td>1-2 hrs</td>\n",
       "      <td>1949 Lackland AFB&amp;#44 TX.  Lights racing acros...</td>\n",
       "      <td>2005-12-16</td>\n",
       "      <td>29.38421</td>\n",
       "      <td>-98.581082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1955-10-10 17:00:00</td>\n",
       "      <td>chester (uk/england)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gb</td>\n",
       "      <td>circle</td>\n",
       "      <td>20</td>\n",
       "      <td>20 seconds</td>\n",
       "      <td>Green/Orange circular disc over Chester&amp;#44 En...</td>\n",
       "      <td>2008-01-21</td>\n",
       "      <td>53.2</td>\n",
       "      <td>-2.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956-10-10 21:00:00</td>\n",
       "      <td>edna</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>circle</td>\n",
       "      <td>20</td>\n",
       "      <td>1/2 hour</td>\n",
       "      <td>My older brother and twin sister were leaving ...</td>\n",
       "      <td>2004-01-17</td>\n",
       "      <td>28.9783333</td>\n",
       "      <td>-96.645833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1960-10-10 20:00:00</td>\n",
       "      <td>kaneohe</td>\n",
       "      <td>hi</td>\n",
       "      <td>us</td>\n",
       "      <td>light</td>\n",
       "      <td>900</td>\n",
       "      <td>15 minutes</td>\n",
       "      <td>AS a Marine 1st Lt. flying an FJ4B fighter/att...</td>\n",
       "      <td>2004-01-22</td>\n",
       "      <td>21.4180556</td>\n",
       "      <td>-157.803611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime                  city state country     shape  \\\n",
       "0  1949-10-10 20:30:00            san marcos    tx      us  cylinder   \n",
       "1  1949-10-10 21:00:00          lackland afb    tx     NaN     light   \n",
       "2  1955-10-10 17:00:00  chester (uk/england)   NaN      gb    circle   \n",
       "3  1956-10-10 21:00:00                  edna    tx      us    circle   \n",
       "4  1960-10-10 20:00:00               kaneohe    hi      us     light   \n",
       "\n",
       "  duration (seconds) duration (hours/min)  \\\n",
       "0               2700           45 minutes   \n",
       "1               7200              1-2 hrs   \n",
       "2                 20           20 seconds   \n",
       "3                 20             1/2 hour   \n",
       "4                900           15 minutes   \n",
       "\n",
       "                                            comments date posted    latitude  \\\n",
       "0  This event took place in early fall around 194...  2004-04-27  29.8830556   \n",
       "1  1949 Lackland AFB&#44 TX.  Lights racing acros...  2005-12-16    29.38421   \n",
       "2  Green/Orange circular disc over Chester&#44 En...  2008-01-21        53.2   \n",
       "3  My older brother and twin sister were leaving ...  2004-01-17  28.9783333   \n",
       "4  AS a Marine 1st Lt. flying an FJ4B fighter/att...  2004-01-22  21.4180556   \n",
       "\n",
       "   longitude   \n",
       "0  -97.941111  \n",
       "1  -98.581082  \n",
       "2   -2.916667  \n",
       "3  -96.645833  \n",
       "4 -157.803611  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ddd4f46-f7a4-41a8-8288-d438bee22382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80332, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d54a9f-2298-4a49-b805-4c9abcac2297",
   "metadata": {},
   "source": [
    "# 1) Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd5bce5-4c0a-45b7-9600-cf4408b86e3a",
   "metadata": {},
   "source": [
    "## 1.1) Column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55368d5b-8e68-4b29-ae48-a049fa897c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'city', 'state', 'country', 'shape', 'duration (seconds)',\n",
       "       'duration (hours/min)', 'comments', 'date posted', 'latitude',\n",
       "       'longitude '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad450f24-dfbf-4865-b24f-2679711c54a1",
   "metadata": {},
   "source": [
    "We notice a 2 issues, that is, the 'longitude' column label is mispelled : it contains a blank space at the end of the string. The other issue is that some other columns names are not very clean: for example, they contains spaces or parenthesis, which can be quite disturbing later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08b0f1bb-8d3d-4af9-9dd8-81136ac30d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns = {'date posted': 'date_posted'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d32562bd-4b20-4097-a4f5-1485baa9a8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace(' ', '', regex = True) # removing spaces\n",
    "df.columns = df.columns.str.replace('(\\/)|(\\()', '_', regex = True)\n",
    "df.columns = df.columns.str.replace('(\\))', '', regex = True)\n",
    "#df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ed09741-47f3-40e1-92f0-a24c3ad49bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'city', 'state', 'country', 'shape', 'duration_seconds',\n",
       "       'duration_hours_min', 'comments', 'date_posted', 'latitude',\n",
       "       'longitude'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27913778-1bac-4a8b-acf1-af1b2622dee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime               object\n",
       "city                   object\n",
       "state                  object\n",
       "country                object\n",
       "shape                  object\n",
       "duration_seconds       object\n",
       "duration_hours_min     object\n",
       "comments               object\n",
       "date_posted            object\n",
       "latitude               object\n",
       "longitude             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b42465-d58f-49e8-a227-b0e88a6e15bd",
   "metadata": {},
   "source": [
    "We also notice that 'longitude' column is a type float, which is pretty logical, whereas 'latitude' column if typed as an object : why ? Let's check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af5587e2-7172-4315-a491-15045b4ef5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration_seconds</th>\n",
       "      <th>duration_hours_min</th>\n",
       "      <th>comments</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43782</th>\n",
       "      <td>1974-05-22 05:30:00</td>\n",
       "      <td>mescalero indian reservation</td>\n",
       "      <td>nm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rectangle</td>\n",
       "      <td>180</td>\n",
       "      <td>two hours</td>\n",
       "      <td>Huge rectangular object emmitting intense whit...</td>\n",
       "      <td>2012-04-18</td>\n",
       "      <td>33q.200088</td>\n",
       "      <td>-105.624152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime                          city state country  \\\n",
       "43782  1974-05-22 05:30:00  mescalero indian reservation    nm     NaN   \n",
       "\n",
       "           shape duration_seconds duration_hours_min  \\\n",
       "43782  rectangle              180          two hours   \n",
       "\n",
       "                                                comments date_posted  \\\n",
       "43782  Huge rectangular object emmitting intense whit...  2012-04-18   \n",
       "\n",
       "         latitude   longitude  \n",
       "43782  33q.200088 -105.624152  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['latitude'].astype(str).str.contains('[a-zA-Z]')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67706f7-3d1f-41ae-93b2-5f8d13ea4f4b",
   "metadata": {},
   "source": [
    "We see that this problem is probably due to a typo: the corresponding latitude for 'mescalero indian reservation' contains a letter ('q'). Since this issue only concerns a single row, we can check the real latitude of this place on the Internet (if there were too many rows, we would have chosen another soluton). It turns out that the real latitude is 33.2 so the error was indeed the result of a typo, so we can remove the misplaced letter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb8b9979-4283-4522-9cee-40b43cdb62a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['latitude'] = pd.to_numeric(df['latitude'].astype(str).str.extract('(\\d+.\\d+|\\d+)', expand = False))\n",
    "#df.dtypes #now both of the 'latitude' and 'longitude' columns have the right type!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764723fd-5035-41c4-aad1-29d00613ad45",
   "metadata": {},
   "source": [
    "We have the same issue with the \"duration\" column, so let's fix it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c1e4ddc-a092-4a4c-a829-a31b2253655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"duration_seconds\"] = pd.to_numeric(df['duration_seconds'].astype(str).str.extract('(\\d+.\\d+|\\d+)', expand = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8867a684-6f74-4f64-a704-2220dbcfc15b",
   "metadata": {},
   "source": [
    "## 1.2) Handling NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdd68042-7569-4865-ab73-2b14310ec468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>9670</td>\n",
       "      <td>12.037544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>5797</td>\n",
       "      <td>7.216302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shape</th>\n",
       "      <td>1932</td>\n",
       "      <td>2.405019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comments</th>\n",
       "      <td>15</td>\n",
       "      <td>0.018673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_seconds</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_hours_min</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_posted</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     sum       perc\n",
       "country             9670  12.037544\n",
       "state               5797   7.216302\n",
       "shape               1932   2.405019\n",
       "comments              15   0.018673\n",
       "datetime               0   0.000000\n",
       "city                   0   0.000000\n",
       "duration_seconds       0   0.000000\n",
       "duration_hours_min     0   0.000000\n",
       "date_posted            0   0.000000\n",
       "latitude               0   0.000000\n",
       "longitude              0   0.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_na(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dd4be0-9ed6-4d66-9903-07c2c25e5bb0",
   "metadata": {},
   "source": [
    "We notice that there are quite a lot of NaN values in both \"country\" and \"state\" columns. Let's see a few rows that are concerned by this phenomenon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01e63d5a-0db9-4066-994a-ab8b41a48e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration_seconds</th>\n",
       "      <th>duration_hours_min</th>\n",
       "      <th>comments</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949-10-10 21:00:00</td>\n",
       "      <td>lackland afb</td>\n",
       "      <td>tx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>light</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>1-2 hrs</td>\n",
       "      <td>1949 Lackland AFB&amp;#44 TX.  Lights racing acros...</td>\n",
       "      <td>2005-12-16</td>\n",
       "      <td>29.384210</td>\n",
       "      <td>-98.581082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1955-10-10 17:00:00</td>\n",
       "      <td>chester (uk/england)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gb</td>\n",
       "      <td>circle</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20 seconds</td>\n",
       "      <td>Green/Orange circular disc over Chester&amp;#44 En...</td>\n",
       "      <td>2008-01-21</td>\n",
       "      <td>53.200000</td>\n",
       "      <td>-2.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1965-10-10 21:00:00</td>\n",
       "      <td>penarth (uk/wales)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gb</td>\n",
       "      <td>circle</td>\n",
       "      <td>180.0</td>\n",
       "      <td>about 3 mins</td>\n",
       "      <td>penarth uk  circle  3mins  stayed 30ft above m...</td>\n",
       "      <td>2006-02-14</td>\n",
       "      <td>51.434722</td>\n",
       "      <td>-3.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1973-10-10 23:00:00</td>\n",
       "      <td>bermuda nas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>light</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20 sec.</td>\n",
       "      <td>saw fast moving blip on the radar scope thin w...</td>\n",
       "      <td>2002-01-11</td>\n",
       "      <td>32.364167</td>\n",
       "      <td>-64.678611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1974-10-10 21:30:00</td>\n",
       "      <td>cardiff (uk/wales)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gb</td>\n",
       "      <td>disk</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>20 minutes</td>\n",
       "      <td>back in 1974 I was 19 at the time and  lived i...</td>\n",
       "      <td>2007-02-01</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>-3.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80254</th>\n",
       "      <td>2009-09-09 21:15:00</td>\n",
       "      <td>nottinghamshire (uk/england)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gb</td>\n",
       "      <td>fireball</td>\n",
       "      <td>600.0</td>\n",
       "      <td>10 mins</td>\n",
       "      <td>resembled orange flame imagine a transparent h...</td>\n",
       "      <td>2009-12-12</td>\n",
       "      <td>53.166667</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80255</th>\n",
       "      <td>2009-09-09 21:38:00</td>\n",
       "      <td>kaiserlautern (germany)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>de</td>\n",
       "      <td>light</td>\n",
       "      <td>40.0</td>\n",
       "      <td>about 40 seconds</td>\n",
       "      <td>2 white lights over Kaiserslautern&amp;#44 ramstei...</td>\n",
       "      <td>2009-12-12</td>\n",
       "      <td>49.450000</td>\n",
       "      <td>7.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80319</th>\n",
       "      <td>2013-09-09 20:15:00</td>\n",
       "      <td>clifton</td>\n",
       "      <td>nj</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>~1hr+</td>\n",
       "      <td>Luminous line seen in New Jersey sky.</td>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>40.858433</td>\n",
       "      <td>-74.163755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80322</th>\n",
       "      <td>2013-09-09 21:00:00</td>\n",
       "      <td>aleksandrow (poland)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>light</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15 seconds</td>\n",
       "      <td>Two points of light following one another in a...</td>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>50.465843</td>\n",
       "      <td>22.891814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80324</th>\n",
       "      <td>2013-09-09 21:00:00</td>\n",
       "      <td>hamstead (hollyridge)</td>\n",
       "      <td>nc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>light</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2 minutes</td>\n",
       "      <td>8 to ten lights bright orange in color large t...</td>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>34.367594</td>\n",
       "      <td>-77.710548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12211 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime                          city state country  \\\n",
       "1      1949-10-10 21:00:00                  lackland afb    tx     NaN   \n",
       "2      1955-10-10 17:00:00          chester (uk/england)   NaN      gb   \n",
       "6      1965-10-10 21:00:00            penarth (uk/wales)   NaN      gb   \n",
       "18     1973-10-10 23:00:00                   bermuda nas   NaN     NaN   \n",
       "20     1974-10-10 21:30:00            cardiff (uk/wales)   NaN      gb   \n",
       "...                    ...                           ...   ...     ...   \n",
       "80254  2009-09-09 21:15:00  nottinghamshire (uk/england)   NaN      gb   \n",
       "80255  2009-09-09 21:38:00       kaiserlautern (germany)   NaN      de   \n",
       "80319  2013-09-09 20:15:00                       clifton    nj     NaN   \n",
       "80322  2013-09-09 21:00:00          aleksandrow (poland)   NaN     NaN   \n",
       "80324  2013-09-09 21:00:00         hamstead (hollyridge)    nc     NaN   \n",
       "\n",
       "          shape  duration_seconds duration_hours_min  \\\n",
       "1         light            7200.0            1-2 hrs   \n",
       "2        circle              20.0         20 seconds   \n",
       "6        circle             180.0       about 3 mins   \n",
       "18        light              20.0            20 sec.   \n",
       "20         disk            1200.0         20 minutes   \n",
       "...         ...               ...                ...   \n",
       "80254  fireball             600.0            10 mins   \n",
       "80255     light              40.0   about 40 seconds   \n",
       "80319     other            3600.0              ~1hr+   \n",
       "80322     light              15.0         15 seconds   \n",
       "80324     light             120.0          2 minutes   \n",
       "\n",
       "                                                comments date_posted  \\\n",
       "1      1949 Lackland AFB&#44 TX.  Lights racing acros...  2005-12-16   \n",
       "2      Green/Orange circular disc over Chester&#44 En...  2008-01-21   \n",
       "6      penarth uk  circle  3mins  stayed 30ft above m...  2006-02-14   \n",
       "18     saw fast moving blip on the radar scope thin w...  2002-01-11   \n",
       "20     back in 1974 I was 19 at the time and  lived i...  2007-02-01   \n",
       "...                                                  ...         ...   \n",
       "80254  resembled orange flame imagine a transparent h...  2009-12-12   \n",
       "80255  2 white lights over Kaiserslautern&#44 ramstei...  2009-12-12   \n",
       "80319              Luminous line seen in New Jersey sky.  2013-09-30   \n",
       "80322  Two points of light following one another in a...  2013-09-30   \n",
       "80324  8 to ten lights bright orange in color large t...  2013-09-30   \n",
       "\n",
       "        latitude  longitude  \n",
       "1      29.384210 -98.581082  \n",
       "2      53.200000  -2.916667  \n",
       "6      51.434722  -3.180000  \n",
       "18     32.364167 -64.678611  \n",
       "20     51.500000  -3.200000  \n",
       "...          ...        ...  \n",
       "80254  53.166667  -1.000000  \n",
       "80255  49.450000   7.750000  \n",
       "80319  40.858433 -74.163755  \n",
       "80322  50.465843  22.891814  \n",
       "80324  34.367594 -77.710548  \n",
       "\n",
       "[12211 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('country.isna() | state.isna()', engine = 'python')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110ba804-c01f-43db-a4f0-24a5214e654a",
   "metadata": {},
   "source": [
    "* For the \"state\" column, the problem is likely due to the fact that a \"state\" is commonly used in the US or in Canada, but not in other countries. Thus, we won't touch at this column for the moment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b661831-3f0c-4239-a35b-d2a4812ce857",
   "metadata": {},
   "source": [
    "### 1.2.1 Cleaning \"country\" column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ccdd7d-3625-4cea-b96a-aef33c0a0a92",
   "metadata": {},
   "source": [
    "In a first approach, we decided to fill NaN values in the \"country\" column by searching the corresponding country of the given latitude and longitude (this two columns are always filled). To do so, we will use the \"geopy\" library (geopy is actually a client), which allows to find the country, based on the geographic coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24ece5b8-030b-4afe-bc77-7ae487b3d019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the service\n",
    "geolocator = Nominatim(user_agent=\"begining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27e4ae95-1c5c-4d09-90ce-88f471d38430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partioning our df between missing values and non-missing values\n",
    "df1 = df[df['country'].isna()].reset_index(drop=False)\n",
    "df2 = df[~df['country'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc575d32-8d92-4f90-acec-e9094485b70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape[0] + df2.shape[0] == df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e438a8e7-c576-4cad-9f20-6b225c1b7ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a full coordinate system for each row, based on the latitude and longitude column\n",
    "df1['coords'] = [to_point(x, y) for x, y in zip(df1['latitude'], df1['longitude'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53795ed9-c54c-42af-903d-20fe8eb6b69d",
   "metadata": {},
   "source": [
    "We will apply our functions \"get_geo_feature\" to obtain the country code for each row where the country is missing. **This step might be time costly (approx. 1h30).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab1355a2-f807-48c4-a901-3867e871d58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['country'] = np.vectorize(get_geo_feature)(coord=df1['coords'].values,\n",
    "                                               feature='country_code',\n",
    "                                              geolocator=geolocator).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07f96590-f833-498f-941a-7fc008387380",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['country'] = np.where(df1['country']=='nan', np.nan, df1['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b3976af-c8ba-4278-8bdc-1e90e886c8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "435"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['country'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec263a03-b694-4a3b-a5ac-ec83cf4e695b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop(['coords', 'index'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1d297a-9c3e-4477-8eba-202939537944",
   "metadata": {},
   "source": [
    "The observations where the country was (formerly) missing must be combined with those where the country was known. Thus, we have to binds the rows of the two dataframes in order to get al the observations reunited:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6573cd2-d8e8-45b0-873f-7dc56a378395",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2], ignore_index=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c29f6a9-1897-432a-b37e-10193dc5cfd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80332, 11)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # we got back the shape of the begnining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ad8413-982d-4f84-a253-731a48713805",
   "metadata": {},
   "source": [
    "In a second approach, we will use the information that we have in the \"city\" column: indeed we notice that there is some potential information about the country inside this column (see above)!! But sometimes, this information is not relevant, for example if we look at the tail of the dataframe above, \"hollyridge\" is clearny not a country, but a US state! We have to make sure that if there is additionnal information in the \"city\", this information is actually a country!\n",
    "\n",
    "The easiest way to do this is to use web-scraping to get the list of all countries with the corresponding country codes (country codes will be useful to standardize the country column):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2a379288-3a90-4ff4-8d68-b9d0607bbeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table table-bordered downloads tablesorter\n"
     ]
    }
   ],
   "source": [
    "table = get_table_bs4(URL=\"https://www.iban.com/country-codes\")\n",
    "#print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d7d65dab-8f87-401f-a398-24384ab80e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Alpha-2 code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afghanistan</td>\n",
       "      <td>af</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>åland islands</td>\n",
       "      <td>ax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>albania</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>algeria</td>\n",
       "      <td>dz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>american samoa</td>\n",
       "      <td>as</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Country Alpha-2 code\n",
       "0     afghanistan           af\n",
       "1   åland islands           ax\n",
       "2         albania           al\n",
       "3         algeria           dz\n",
       "4  american samoa           as"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "countries_id = alpha_code_reverse(table, \"Country\", 0, 1)\n",
    "\n",
    "print(countries_id.shape)\n",
    "display(countries_id.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31d037f-756b-45ed-8fcf-8bcc559074fd",
   "metadata": {},
   "source": [
    "Now that we have a list of all the countries in the world, we can first standardize the country column by converting the country codes into country names, for non-missing country values in our dataframe. To do so, we just have to create a dictionnary with both the country-code and the corresponding country name, and then map it to the \"country\" column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45171cd9-b3fe-4ff2-9392-43b743d95161",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_dict = dict(zip(countries_id['Alpha-2 code'], countries_id['Country']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7955bb5b-b501-42d0-8cbd-a6554ad84a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['country'] = df['country'].replace(countries_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4e481b-bacf-4685-a4c1-0540667b096c",
   "metadata": {},
   "source": [
    "Finally, we can easily detect if there is some informative content in the \"city\" column for each row, by comparing it  with the list of the countries that we previously built. In order to perform this step, we will have to use regex: first, we create a \"large pattern\" with our country Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c3caa27-f766-404f-b04f-16dd5fedd2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_countries = '('+ '|'.join(countries_id['Country'].apply(lambda x: re.sub(r'\\((.*)\\)', '', x))) +')'\n",
    "#pattern_countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e96808-911e-4f61-96e5-3f47edc63ce3",
   "metadata": {},
   "source": [
    "Then, we match this pattern with the \"city\" column, for each row (NB: str.extract method is vectorized):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea6b22c3-efd8-4cb3-99bc-dd3ee9a77f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['test'] = df['city'].str.extract(pattern_countries)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bee22c5f-b7ee-4442-b17d-e4964970f027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "435"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.country.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eb5e64-1440-4f4c-bf17-3a347d023ce4",
   "metadata": {},
   "source": [
    "Then, we can replace the values of the country that are missing by the values obtained with our method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "28650c2a-9149-4f3c-bdee-3be2b39e2205",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['country'] = np.where(df['country'].isna(), df['test'], df['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5988442f-5e52-4bb8-8e87-71fd76cbef8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85, 12)\n",
      "(73154, 12)\n",
      "(85, 12)\n"
     ]
    }
   ],
   "source": [
    "print(df[df['country'].isna()].shape)\n",
    "print(df[df['test'].isna()].shape)\n",
    "print(df[df['country'].isna() & df['test'].isna()].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facc6557-9c15-42cf-b3fc-14a4193cfd39",
   "metadata": {},
   "source": [
    "We see that our method allowed to reduce the number of NaN values in the \"country\" column. But there is still some missing values: let's check those rows to see the issue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "39b5fba9-f17a-4ca4-bd3e-ca88a40a6de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "armidale (australi)                                             1\n",
      "atlantic ocean                                                 11\n",
      "atlantic ocean (at sea)                                         1\n",
      "atlantic ocean (between nassau&#44 bahamas&#44 and florida)     1\n",
      "atlantic ocean (between san juan and u.s. virgin isl.)          1\n",
      "atlantic ocean (cv-67 u.s.navy)                                 1\n",
      "atlantic ocean (in flight)                                      2\n",
      "atlantic ocean (inflight)                                       1\n",
      "atlantic ocean (mid-atlantic)                                   1\n",
      "atlantic ocean (middle)                                         1\n",
      "atlantic ocean (off africa)                                     1\n",
      "atlantic ocean (on cruise ship)                                 1\n",
      "atlantic ocean (troopship/ uss rose)                            1\n",
      "atlantic ocean (virgin islands)                                 1\n",
      "bogor                                                           1\n",
      "broken hill                                                     1\n",
      "caicara (venezuela)                                             1\n",
      "cape town                                                       1\n",
      "caribbean sea                                                   4\n",
      "caribbean sea (u.s. navy ship)                                  2\n",
      "caribbean sea (uss w.s. sims)                                   1\n",
      "caribbean sea (venezuela)                                       1\n",
      "caspian sea (south of) (iran)                                   1\n",
      "celta                                                           1\n",
      "cochabamba (bolivia)                                            3\n",
      "darley (australi)                                               1\n",
      "east atlantic ocean                                             1\n",
      "eldorado                                                        2\n",
      "europe                                                          1\n",
      "guayaquil                                                       1\n",
      "ipatinga (minas gerais) (brasil)                                1\n",
      "jakarta-tokyo (inflight)                                        1\n",
      "joan&oacute;polis (brasil)                                      1\n",
      "la paz (bolivia)                                                2\n",
      "la paz/cochabamba/potosi                                        1\n",
      "maceio (brasil)                                                 1\n",
      "mediterranean sea                                               2\n",
      "mediterranean sea (in flight)                                   1\n",
      "monterrico (guatamala)                                          1\n",
      "north atlantic ocean                                            1\n",
      "north atlanticocean                                             1\n",
      "pacific ocean                                                   3\n",
      "pacific ocean (1500mi.sw of u.s.mainland)                       1\n",
      "pacific ocean (approx. 250 mi. over)                            1\n",
      "pacific ocean (in-flight sighting)                              1\n",
      "pacific ocean (in-flight; from tokyo airport to honolulu)       1\n",
      "pacific ocean (near california coast)                           1\n",
      "pacific ocean (near huntington beach)                           1\n",
      "pacific ocean (no state)                                        1\n",
      "pacific ocean (western)                                         1\n",
      "palmerston north                                                1\n",
      "paraparaumu                                                     1\n",
      "persian gulf                                                    1\n",
      "philippine sea (at sea)                                         1\n",
      "piedra blanka (los padres national forest)                      1\n",
      "remote                                                          1\n",
      "s&atilde;o paulo (brasil)                                       1\n",
      "santiago                                                        1\n",
      "sao paulo (brasil)                                              1\n",
      "saquarema (rio de janeiro) (brasil)                             1\n",
      "tirau                                                           1\n",
      "tyrrhenian sea                                                  1\n",
      "westlake village                                                1\n",
      "Name: city, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "print(df[df['test'].isna() & df['country'].isna()]['city'].value_counts().sort_index())\n",
    "\n",
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4fdc63-f680-4a76-b132-4fd58c18d6df",
   "metadata": {},
   "source": [
    "We notice 2 main issues:\n",
    "* the \"city\" column may contain a sea or ocean name. For these rows, we are going to define the country as \"sea\" or \"ocean\";\n",
    "* there is some issues with country names such as \"brazil\", \"bolivia\", \"australia\". For what is possible and easy, we will replace the country names by hand. But for the remaining rows (there aren't many), we will put a NaN value.\n",
    "\n",
    "Hence, we will use our functions \"replace_exceptions\" in order to replace these exceptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "601f2d99-0a6f-4fca-8559-570ce068b0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 12)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['country'].isna())].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ac43ced-5570-49f8-b52c-42cba803d9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['country'] = np.where((df['test'].isna() & df['country'].isna()), df['city'].apply(replace_exceptions), df['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ee173ffe-8692-4586-bb34-a9861687487f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 12)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['country'].isna())].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a84fce3-806c-42b2-8a5c-dc315c5ba7af",
   "metadata": {},
   "source": [
    "For the country name that are still missing, we decided to delete them, because they are very few of them, we decided to let them as NaN values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f65628-552c-4766-8779-43eedc547f96",
   "metadata": {},
   "source": [
    "## 1.3) Cleaning 'city' column\n",
    "\n",
    "If we have a closer look to this column, we see that the values are not harmonized and can be confusing and noisy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8007317f-28a3-4d45-9807-cbbd412ff96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration_seconds</th>\n",
       "      <th>duration_hours_min</th>\n",
       "      <th>comments</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1979-10-10 22:00:00</td>\n",
       "      <td>saddle lake (canada)</td>\n",
       "      <td>ab</td>\n",
       "      <td>canada</td>\n",
       "      <td>triangle</td>\n",
       "      <td>270.0</td>\n",
       "      <td>4.5 or more min.</td>\n",
       "      <td>Lights far above&amp;#44  that glance; then flee f...</td>\n",
       "      <td>2005-01-19</td>\n",
       "      <td>53.970571</td>\n",
       "      <td>-111.689885</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1982-10-10 07:00:00</td>\n",
       "      <td>gisborne (new zealand)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>new zealand</td>\n",
       "      <td>disk</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2min</td>\n",
       "      <td>gisborne nz 1982 wainui beach to sponge bay</td>\n",
       "      <td>2002-01-11</td>\n",
       "      <td>38.662334</td>\n",
       "      <td>178.017649</td>\n",
       "      <td>new zealand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1993-10-10 03:00:00</td>\n",
       "      <td>zlatoust (russia)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>russian federation (the)</td>\n",
       "      <td>sphere</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>20 minutes</td>\n",
       "      <td>I woke up at night and looked out the window n...</td>\n",
       "      <td>2004-12-14</td>\n",
       "      <td>55.183333</td>\n",
       "      <td>59.650000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1996-10-10 20:00:00</td>\n",
       "      <td>lake macquarie (nsw&amp;#44 australia)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>australia</td>\n",
       "      <td>light</td>\n",
       "      <td>300.0</td>\n",
       "      <td>5 min</td>\n",
       "      <td>RED LIGHT WITH OTHER RED FLASHING LIGHT&amp;#44 ON...</td>\n",
       "      <td>1999-05-24</td>\n",
       "      <td>33.093373</td>\n",
       "      <td>151.588982</td>\n",
       "      <td>australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1999-10-10 22:30:00</td>\n",
       "      <td>casey key (north end of)</td>\n",
       "      <td>fl</td>\n",
       "      <td>united states of america (the)</td>\n",
       "      <td>triangle</td>\n",
       "      <td>120.0</td>\n",
       "      <td>several minutes</td>\n",
       "      <td>A large trianglual shaped craft flew from hori...</td>\n",
       "      <td>2002-09-19</td>\n",
       "      <td>27.150053</td>\n",
       "      <td>-82.480653</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80298</th>\n",
       "      <td>2012-09-09 14:00:00</td>\n",
       "      <td>pictou (canada)</td>\n",
       "      <td>ns</td>\n",
       "      <td>canada</td>\n",
       "      <td>disk</td>\n",
       "      <td>600.0</td>\n",
       "      <td>10 minutes</td>\n",
       "      <td>Spotted a object over the town&amp;#39s business d...</td>\n",
       "      <td>2012-09-24</td>\n",
       "      <td>45.666667</td>\n",
       "      <td>-62.700000</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80311</th>\n",
       "      <td>2012-09-09 21:00:00</td>\n",
       "      <td>new york city (brooklyn)</td>\n",
       "      <td>ny</td>\n",
       "      <td>united states of america (the)</td>\n",
       "      <td>light</td>\n",
       "      <td>1290.0</td>\n",
       "      <td>21:30</td>\n",
       "      <td>Glowing&amp;#44 circular lights visible in the clo...</td>\n",
       "      <td>2012-09-24</td>\n",
       "      <td>40.714167</td>\n",
       "      <td>-74.006389</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80317</th>\n",
       "      <td>2013-09-09 01:50:00</td>\n",
       "      <td>buffalo (west of; on highway 90 west)</td>\n",
       "      <td>ny</td>\n",
       "      <td>united states of america (the)</td>\n",
       "      <td>triangle</td>\n",
       "      <td>180.0</td>\n",
       "      <td>3 minutes</td>\n",
       "      <td>Massive Flat Black triangle  with 3 red lights.</td>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>42.886389</td>\n",
       "      <td>-78.878611</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80321</th>\n",
       "      <td>2013-09-09 13:10:00</td>\n",
       "      <td>calmar (canada)</td>\n",
       "      <td>ab</td>\n",
       "      <td>canada</td>\n",
       "      <td>unknown</td>\n",
       "      <td>90.0</td>\n",
       "      <td>45-90 seconds</td>\n",
       "      <td>Fastest dot I have ever seen in the sky&amp;#33</td>\n",
       "      <td>2013-09-09</td>\n",
       "      <td>53.250000</td>\n",
       "      <td>-113.783333</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80325</th>\n",
       "      <td>2013-09-09 21:00:00</td>\n",
       "      <td>milton (canada)</td>\n",
       "      <td>on</td>\n",
       "      <td>canada</td>\n",
       "      <td>fireball</td>\n",
       "      <td>180.0</td>\n",
       "      <td>3 minutes</td>\n",
       "      <td>Massive Bright Orange Fireball in Sky</td>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>46.300000</td>\n",
       "      <td>-63.216667</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12466 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime                                   city state  \\\n",
       "2      1979-10-10 22:00:00                   saddle lake (canada)    ab   \n",
       "3      1982-10-10 07:00:00                 gisborne (new zealand)   NaN   \n",
       "6      1993-10-10 03:00:00                      zlatoust (russia)   NaN   \n",
       "8      1996-10-10 20:00:00     lake macquarie (nsw&#44 australia)   NaN   \n",
       "10     1999-10-10 22:30:00               casey key (north end of)    fl   \n",
       "...                    ...                                    ...   ...   \n",
       "80298  2012-09-09 14:00:00                        pictou (canada)    ns   \n",
       "80311  2012-09-09 21:00:00               new york city (brooklyn)    ny   \n",
       "80317  2013-09-09 01:50:00  buffalo (west of; on highway 90 west)    ny   \n",
       "80321  2013-09-09 13:10:00                        calmar (canada)    ab   \n",
       "80325  2013-09-09 21:00:00                        milton (canada)    on   \n",
       "\n",
       "                              country     shape  duration_seconds  \\\n",
       "2                              canada  triangle             270.0   \n",
       "3                         new zealand      disk             120.0   \n",
       "6            russian federation (the)    sphere            1200.0   \n",
       "8                           australia     light             300.0   \n",
       "10     united states of america (the)  triangle             120.0   \n",
       "...                               ...       ...               ...   \n",
       "80298                          canada      disk             600.0   \n",
       "80311  united states of america (the)     light            1290.0   \n",
       "80317  united states of america (the)  triangle             180.0   \n",
       "80321                          canada   unknown              90.0   \n",
       "80325                          canada  fireball             180.0   \n",
       "\n",
       "      duration_hours_min                                           comments  \\\n",
       "2       4.5 or more min.  Lights far above&#44  that glance; then flee f...   \n",
       "3                   2min        gisborne nz 1982 wainui beach to sponge bay   \n",
       "6             20 minutes  I woke up at night and looked out the window n...   \n",
       "8                  5 min  RED LIGHT WITH OTHER RED FLASHING LIGHT&#44 ON...   \n",
       "10       several minutes  A large trianglual shaped craft flew from hori...   \n",
       "...                  ...                                                ...   \n",
       "80298         10 minutes  Spotted a object over the town&#39s business d...   \n",
       "80311              21:30  Glowing&#44 circular lights visible in the clo...   \n",
       "80317          3 minutes    Massive Flat Black triangle  with 3 red lights.   \n",
       "80321      45-90 seconds        Fastest dot I have ever seen in the sky&#33   \n",
       "80325          3 minutes              Massive Bright Orange Fireball in Sky   \n",
       "\n",
       "      date_posted   latitude   longitude         test  \n",
       "2      2005-01-19  53.970571 -111.689885       canada  \n",
       "3      2002-01-11  38.662334  178.017649  new zealand  \n",
       "6      2004-12-14  55.183333   59.650000          NaN  \n",
       "8      1999-05-24  33.093373  151.588982    australia  \n",
       "10     2002-09-19  27.150053  -82.480653          NaN  \n",
       "...           ...        ...         ...          ...  \n",
       "80298  2012-09-24  45.666667  -62.700000       canada  \n",
       "80311  2012-09-24  40.714167  -74.006389          NaN  \n",
       "80317  2013-09-30  42.886389  -78.878611          NaN  \n",
       "80321  2013-09-09  53.250000 -113.783333       canada  \n",
       "80325  2013-09-30  46.300000  -63.216667       canada  \n",
       "\n",
       "[12466 rows x 12 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query(\"city.str.contains('\\(') | city.str.contains('\\)')\", engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69ce709-d20e-4426-baf2-cce44c202179",
   "metadata": {},
   "source": [
    "We have to remove all parenthesis from this column. Then, we have to harmonize the city name; and we will eventually standardize this column by capitalizing the city names and to remove white spaces for a single-word-city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "01868c35-355a-457e-9149-2c3b38f2b576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19900\n",
      "18386\n",
      "18290\n",
      "18290\n"
     ]
    }
   ],
   "source": [
    "df = clean_city_col(df=df)\n",
    "# the number of differents city values at each step of the processing is decreasing: perfect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e54d0d-7b64-43ec-949b-f051900be69b",
   "metadata": {},
   "source": [
    "Our processing of the city column has resulted in the harmonization and standardization of city names. This achievement will be very convenient for the interactive map that we are going to create and also for an in-depth statistical analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cce6b27-2941-47b6-a2f9-dd9bd1ce5b4c",
   "metadata": {},
   "source": [
    "## 1.4) Cleaning \"shape\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "80bb292d-af67-46b0-87e9-71f5a4890fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "light        16565\n",
       "triangle      7865\n",
       "circle        7608\n",
       "fireball      6208\n",
       "other         5649\n",
       "unknown       5584\n",
       "sphere        5387\n",
       "disk          5213\n",
       "oval          3733\n",
       "formation     2457\n",
       "cigar         2057\n",
       "changing      1962\n",
       "flash         1328\n",
       "rectangle     1297\n",
       "cylinder      1283\n",
       "diamond       1178\n",
       "chevron        952\n",
       "egg            759\n",
       "teardrop       750\n",
       "cone           316\n",
       "cross          233\n",
       "delta            7\n",
       "crescent         2\n",
       "round            2\n",
       "dome             1\n",
       "pyramid          1\n",
       "flare            1\n",
       "hexagon          1\n",
       "changed          1\n",
       "Name: shape, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"shape\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf4b410-e574-4c57-8d5e-5055e61e3021",
   "metadata": {},
   "source": [
    "## 1.4) Cleaning \"datetime\" column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7cfbdc-7009-43cf-865e-564a8d89d0cd",
   "metadata": {},
   "source": [
    "Here we just want to standardize the format of the date. No missing values. Other changes will be done for in the webapp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "04e60334-910d-4beb-a37a-fd262386b1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "format='%Y-%m-%d %H:%M:%S'\n",
    "df['datetime'] = pd.to_datetime(df['datetime'], format=format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5d758b-c71d-4e43-8d2a-c237dbf23973",
   "metadata": {},
   "source": [
    "## 1.5) Cleaning \"state\" column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d484e5f-eb2d-4407-a0b9-3548c133d654",
   "metadata": {},
   "source": [
    "Here we just need to replace the US states codes by their names. We will use again webscrapping to match the alpha code of each state with its full name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f7eeafc9-051e-4e93-97bf-b92437f42375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table table-bordered responsive-utilities table-hover table-condensed mrgn-bttm-0\n"
     ]
    }
   ],
   "source": [
    "table = get_table_bs4(URL=\"https://www23.statcan.gc.ca/imdb/p3VD.pl?Function=getVD&TVD=53971\")\n",
    "#print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "81df4a76-5052-4545-b010-bafd52d386df",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_id = alpha_code_reverse(table, \"State\", 0, 2)\n",
    "#states_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a3bd0e89-0932-468b-9cf9-d1b33f06af07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5797"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"state\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "754fba1b-d0e9-4d76-9a9e-3d9367255b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"country\"] == \"united states of america (the)\"][\"state\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "11b6fafd-663c-4aba-8cbb-1561b86e5654",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_dict = dict(zip(states_id['Alpha-2 code'], states_id['State']))\n",
    "df['state'] = df['state'].replace(states_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "af1c2c37-c9a3-4d90-9f0b-ec5abc0a20fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5797"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"state\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "aabf75d1-5653-4c67-a5ea-37cd6152adf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"country\"] == \"united states of america (the)\"][\"state\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7eb9c563-d590-42d1-8d25-330e0170ab89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration_seconds</th>\n",
       "      <th>duration_hours_min</th>\n",
       "      <th>comments</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949-10-10 21:00:00</td>\n",
       "      <td>Lackland Afb</td>\n",
       "      <td>texas</td>\n",
       "      <td>united states of america (the)</td>\n",
       "      <td>light</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>1-2 hrs</td>\n",
       "      <td>1949 Lackland AFB&amp;#44 TX.  Lights racing acros...</td>\n",
       "      <td>2005-12-16</td>\n",
       "      <td>29.384210</td>\n",
       "      <td>-98.581082</td>\n",
       "      <td>texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1973-10-10 23:00:00</td>\n",
       "      <td>Bermuda Nas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bermuda</td>\n",
       "      <td>light</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20 sec.</td>\n",
       "      <td>saw fast moving blip on the radar scope thin w...</td>\n",
       "      <td>2002-01-11</td>\n",
       "      <td>32.364167</td>\n",
       "      <td>-64.678611</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1979-10-10 22:00:00</td>\n",
       "      <td>Saddle Lake</td>\n",
       "      <td>ab</td>\n",
       "      <td>canada</td>\n",
       "      <td>triangle</td>\n",
       "      <td>270.0</td>\n",
       "      <td>4.5 or more min.</td>\n",
       "      <td>Lights far above&amp;#44  that glance; then flee f...</td>\n",
       "      <td>2005-01-19</td>\n",
       "      <td>53.970571</td>\n",
       "      <td>-111.689885</td>\n",
       "      <td>ab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1982-10-10 07:00:00</td>\n",
       "      <td>Gisborne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>new zealand</td>\n",
       "      <td>disk</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2min</td>\n",
       "      <td>gisborne nz 1982 wainui beach to sponge bay</td>\n",
       "      <td>2002-01-11</td>\n",
       "      <td>38.662334</td>\n",
       "      <td>178.017649</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1986-10-10 20:00:00</td>\n",
       "      <td>Holmespawling</td>\n",
       "      <td>new york</td>\n",
       "      <td>united states of america (the)</td>\n",
       "      <td>chevron</td>\n",
       "      <td>180.0</td>\n",
       "      <td>3 minutes</td>\n",
       "      <td>Football Field Sized Chevron with bright white...</td>\n",
       "      <td>2007-10-08</td>\n",
       "      <td>41.523427</td>\n",
       "      <td>-73.646795</td>\n",
       "      <td>new york</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime           city     state  \\\n",
       "0 1949-10-10 21:00:00   Lackland Afb     texas   \n",
       "1 1973-10-10 23:00:00    Bermuda Nas       NaN   \n",
       "2 1979-10-10 22:00:00   Saddle Lake         ab   \n",
       "3 1982-10-10 07:00:00      Gisborne        NaN   \n",
       "4 1986-10-10 20:00:00  Holmespawling  new york   \n",
       "\n",
       "                          country     shape  duration_seconds  \\\n",
       "0  united states of america (the)     light            7200.0   \n",
       "1                         bermuda     light              20.0   \n",
       "2                          canada  triangle             270.0   \n",
       "3                     new zealand      disk             120.0   \n",
       "4  united states of america (the)   chevron             180.0   \n",
       "\n",
       "  duration_hours_min                                           comments  \\\n",
       "0            1-2 hrs  1949 Lackland AFB&#44 TX.  Lights racing acros...   \n",
       "1            20 sec.  saw fast moving blip on the radar scope thin w...   \n",
       "2   4.5 or more min.  Lights far above&#44  that glance; then flee f...   \n",
       "3               2min        gisborne nz 1982 wainui beach to sponge bay   \n",
       "4          3 minutes  Football Field Sized Chevron with bright white...   \n",
       "\n",
       "  date_posted   latitude   longitude      test  \n",
       "0  2005-12-16  29.384210  -98.581082     texas  \n",
       "1  2002-01-11  32.364167  -64.678611       NaN  \n",
       "2  2005-01-19  53.970571 -111.689885        ab  \n",
       "3  2002-01-11  38.662334  178.017649       NaN  \n",
       "4  2007-10-08  41.523427  -73.646795  new york  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8948d2-f12c-4b8a-81cd-fc47c0b02b47",
   "metadata": {},
   "source": [
    "It seems to have worked!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93df55e5-f331-4893-89d5-d9b1de81ad7a",
   "metadata": {},
   "source": [
    "## next###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e46cc4a2-28fb-4e52-873f-3677b43f8b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    This event took place in early fall around 194...\n",
       "1    1949 Lackland AFB&#44 TX.  Lights racing acros...\n",
       "2    Green/Orange circular disc over Chester&#44 En...\n",
       "3    My older brother and twin sister were leaving ...\n",
       "4    AS a Marine 1st Lt. flying an FJ4B fighter/att...\n",
       "Name: comments, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"comments\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504519c4-80ea-4427-bffb-e5d84bead0d2",
   "metadata": {},
   "source": [
    "# 2) Data Exportation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "09384fa3-56ea-44bb-ad1f-e5b42f695416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>5797</td>\n",
       "      <td>7.216302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shape</th>\n",
       "      <td>1932</td>\n",
       "      <td>2.405019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>20</td>\n",
       "      <td>0.024897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comments</th>\n",
       "      <td>15</td>\n",
       "      <td>0.018673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_seconds</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_hours_min</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_posted</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     sum      perc\n",
       "state               5797  7.216302\n",
       "shape               1932  2.405019\n",
       "country               20  0.024897\n",
       "comments              15  0.018673\n",
       "datetime               0  0.000000\n",
       "city                   0  0.000000\n",
       "duration_seconds       0  0.000000\n",
       "duration_hours_min     0  0.000000\n",
       "date_posted            0  0.000000\n",
       "latitude               0  0.000000\n",
       "longitude              0  0.000000"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_na(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6059cce0-55e0-4b3b-beef-9aa8069f68ed",
   "metadata": {},
   "source": [
    "Since we have clean our data, we should export it into a new .csv file, so as to facilitate oru collaborative work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b3f10994-3af7-4b3e-8f16-9b82c950b56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/ufo_sightings_clean.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
